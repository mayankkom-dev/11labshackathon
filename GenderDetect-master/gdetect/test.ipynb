{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genderdetect as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gender \u001b[39m=\u001b[39m gd\u001b[39m.\u001b[39;49midentify_gender(\u001b[39m'\u001b[39;49m\u001b[39m../../clip_audio_seg/hindi_movie_clip_1/audio_20.wav\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/lablabai/GenderDetect-master/gdetect/genderdetect.py:123\u001b[0m, in \u001b[0;36midentify_gender\u001b[0;34m(filename, block)\u001b[0m\n\u001b[1;32m    121\u001b[0m name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(filename))[\u001b[39m0\u001b[39m]\n\u001b[1;32m    122\u001b[0m gender \u001b[39m=\u001b[39m extract_gender(osegfile)\n\u001b[0;32m--> 123\u001b[0m num_speakers \u001b[39m=\u001b[39m count_speakers(segfile)\n\u001b[1;32m    124\u001b[0m \u001b[39mreturn\u001b[39;00m gender, num_speakers\n",
      "File \u001b[0;32m~/lablabai/GenderDetect-master/gdetect/genderdetect.py:81\u001b[0m, in \u001b[0;36mcount_speakers\u001b[0;34m(segfile)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39mCount the number of unique speakers in the segmentation file.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m speaker_ids \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m---> 81\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(segfile, \u001b[39m'\u001b[39;49m\u001b[39mr+\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m seg:\n\u001b[1;32m     82\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m seg:\n\u001b[1;32m     83\u001b[0m         \u001b[39mprint\u001b[39m(line)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "gender = gd.identify_gender('../../clip_audio_seg/hindi_movie_clip_1/audio_20.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd.identify_gender('../../audio_female_1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0]), -1, -1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/labaipy3.10/lib/python3.10/site-packages/sklearn/base.py:347: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 0.24.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/mayank/miniconda3/envs/labaipy3.10/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m num_speakers\n\u001b[1;32m     16\u001b[0m audio_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../../clip_audio_seg/hindi_movie_clip_1/audio_4.wav\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# clip_srt/hindi_movie_clip_1.wav\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m num_speakers \u001b[39m=\u001b[39m count_speakers(audio_file)\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of speakers in the audio clip: \u001b[39m\u001b[39m{\u001b[39;00mnum_speakers\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m, in \u001b[0;36mcount_speakers\u001b[0;34m(audio_file)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(result)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Extract the speaker IDs\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m speaker_ids \u001b[39m=\u001b[39m \u001b[39mset\u001b[39;49m(speaker_id \u001b[39mfor\u001b[39;49;00m _, _, speaker_id \u001b[39min\u001b[39;49;00m result)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Get the number of speakers\u001b[39;00m\n\u001b[1;32m     11\u001b[0m num_speakers \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(speaker_ids)\n",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(result)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Extract the speaker IDs\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m speaker_ids \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(speaker_id \u001b[39mfor\u001b[39;00m _, _, speaker_id \u001b[39min\u001b[39;00m result)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Get the number of speakers\u001b[39;00m\n\u001b[1;32m     11\u001b[0m num_speakers \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(speaker_ids)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "from pyAudioAnalysis import audioSegmentation\n",
    "\n",
    "def count_speakers(audio_file):\n",
    "    # Perform diarization\n",
    "    result = audioSegmentation.speaker_diarization(audio_file, 2)\n",
    "    print(result)\n",
    "    # Extract the speaker IDs\n",
    "    speaker_ids = set(speaker_id for _, _, speaker_id in result)\n",
    "\n",
    "    # Get the number of speakers\n",
    "    num_speakers = len(speaker_ids)\n",
    "    \n",
    "    return num_speakers\n",
    "\n",
    "\n",
    "audio_file = \"../../clip_audio_seg/hindi_movie_clip_1/audio_4.wav\" # clip_srt/hindi_movie_clip_1.wav\n",
    "num_speakers = count_speakers(audio_file)\n",
    "print(f\"Number of speakers in the audio clip: {num_speakers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m../../clip_audio_seg/hindi_movie_clip_1/audio_4.wav\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m transcript \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mAudio\u001b[39m.\u001b[39;49mtranscribe(\u001b[39m\"\u001b[39;49m\u001b[39mwhisper-1\u001b[39;49m\u001b[39m\"\u001b[39;49m, f)\n",
      "File \u001b[0;32m~/miniconda3/envs/labaipy3.10/lib/python3.10/site-packages/pyAudioAnalysis/../openai/api_resources/audio.py:65\u001b[0m, in \u001b[0;36mAudio.transcribe\u001b[0;34m(cls, model, file, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[1;32m     55\u001b[0m requestor, files, data \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_prepare_request(\n\u001b[1;32m     56\u001b[0m     file\u001b[39m=\u001b[39mfile,\n\u001b[1;32m     57\u001b[0m     filename\u001b[39m=\u001b[39mfile\u001b[39m.\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     64\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_url(\u001b[39m\"\u001b[39m\u001b[39mtranscriptions\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, files\u001b[39m=\u001b[39;49mfiles, params\u001b[39m=\u001b[39;49mdata)\n\u001b[1;32m     66\u001b[0m \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[1;32m     67\u001b[0m     response, api_key, api_version, organization\n\u001b[1;32m     68\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/labaipy3.10/lib/python3.10/site-packages/pyAudioAnalysis/../openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/envs/labaipy3.10/lib/python3.10/site-packages/pyAudioAnalysis/../openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/labaipy3.10/lib/python3.10/site-packages/pyAudioAnalysis/../openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "f = open(\"../../clip_audio_seg/hindi_movie_clip_1/audio_4.wav\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Obtaining dependency information for plotly from https://files.pythonhosted.org/packages/a5/07/5bef9376c975ce23306d9217ab69ca94c07f2a3c90b17c03e3ae4db87170/plotly-5.15.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached plotly-5.15.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tenacity>=6.2.0 (from plotly)\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: packaging in /home/mayank/miniconda3/envs/labaipy3.10/lib/python3.10/site-packages (from plotly) (23.1)\n",
      "Using cached plotly-5.15.0-py2.py3-none-any.whl (15.5 MB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.15.0 tenacity-8.2.2\n"
     ]
    }
   ],
   "source": [
    "! pip install plotly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labaipy3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
